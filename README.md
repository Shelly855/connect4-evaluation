# Connect 4 – Agent Performance Evaluation (Visualisation)

This notebook visualises performance metrics from pre-run Connect 4 agent simulations.

It does **not run games or simulations itself** - it uses the results already saved in `game_results.csv`.

---

## What It Does

- Loads and analyses results from 500 simulated games per matchup
- Visualises:
  - Win/draw rates
  - Win types
  - Execution time and memory usage
  - Minimax metrics (nodes expanded, depth, branching factor, heuristic delta)
- Generates clean summary tables and bar charts for comparison
- Outputs a CSV file with aggregated summary metrics

---

## Files

- `performance_evaluation.ipynb` – Notebook for analysing and visualising performance  
- `game_results.csv` – Raw match results (pre-generated)  
- `summary_metrics.csv` – Aggregated performance metrics per matchup

---

## Notes

- `summary_metrics.csv` was generated by running the notebook in this folder
- `game_results.csv` was generated by running `python performance_evaluation.py` in the main game folder (`connect4-ai`)

---

## Optional Setup (Not Required)

If you'd like to rerun the notebook locally:

1. Ensure Python 3 is installed.
2. Install required packages:
   ```bash
   pip install numpy pandas scikit-learn matplotlib seaborn psutil
   ```
3. Open and run the notebook: `performance_evaluation.ipynb`
> This notebook was created and tested in Jupyter Notebook. You can also open it in VS Code with the Jupyter extension.

---

## GitHub Version (Optional)

[View this folder on GitHub](https://github.com/Shelly855/connect4-evaluation)  
> **Note:** This link is optional and not required for marking. The GitHub version may be updated after submission.
